{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aba926c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\samba\\anaconda\\lib\\site-packages (1.2.4)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\samba\\anaconda\\lib\\site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\users\\samba\\anaconda\\lib\\site-packages (from pandas) (1.20.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\samba\\anaconda\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\samba\\anaconda\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\samba\\anaconda\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\samba\\anaconda\\lib\\site-packages (from tensorflow) (3.15.8)\n",
      "Requirement already satisfied: gast>=0.2.1 in c:\\users\\samba\\anaconda\\lib\\site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in c:\\users\\samba\\anaconda\\lib\\site-packages (from tensorflow) (2.8.0.dev2021122109)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\samba\\anaconda\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\samba\\anaconda\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\samba\\anaconda\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: tensorboard<2.9,>=2.8 in c:\\users\\samba\\anaconda\\lib\\site-packages (from tensorflow) (2.8.0)\n",
      "Requirement already satisfied: libclang>=9.0.1 in c:\\users\\samba\\anaconda\\lib\\site-packages (from tensorflow) (13.0.0)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in c:\\users\\samba\\anaconda\\lib\\site-packages (from tensorflow) (1.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\samba\\anaconda\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\samba\\anaconda\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\samba\\anaconda\\lib\\site-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\samba\\anaconda\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\samba\\anaconda\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\samba\\anaconda\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\samba\\anaconda\\lib\\site-packages (from tensorflow) (1.44.0)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\samba\\anaconda\\lib\\site-packages (from tensorflow) (1.20.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\samba\\anaconda\\lib\\site-packages (from tensorflow) (0.24.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\samba\\anaconda\\lib\\site-packages (from tensorflow) (52.0.0.post20210125)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in c:\\users\\samba\\anaconda\\lib\\site-packages (from tensorflow) (2.0)\n",
      "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in c:\\users\\samba\\anaconda\\lib\\site-packages (from tensorflow) (2.8.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\samba\\anaconda\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.36.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\samba\\anaconda\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.25.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\samba\\anaconda\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\samba\\anaconda\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\samba\\anaconda\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\samba\\anaconda\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.21.3)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\samba\\anaconda\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\samba\\anaconda\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\samba\\anaconda\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\samba\\anaconda\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\samba\\anaconda\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\samba\\anaconda\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\samba\\anaconda\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.3)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\samba\\anaconda\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\samba\\anaconda\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\samba\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\samba\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\samba\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\samba\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\samba\\anaconda\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n",
      "Requirement already satisfied: keras in c:\\users\\samba\\anaconda\\lib\\site-packages (2.8.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install tensorflow\n",
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71100594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D\n",
    "from keras.applications.vgg16 import VGG16\n",
    "print(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b13224",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2df8d9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir= 'C:\\\\Users\\\\samba\\\\Downloads\\\\archive\\\\real_and_fake_face\\\\train_sample'\n",
    "valid_dir= 'C:\\\\Users\\\\samba\\\\Downloads\\\\archive\\\\real_and_fake_face\\\\Test_sample'\n",
    "img_width,img_height = 600, 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1fed0ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n",
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 600, 600, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 600, 600, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 600, 600, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 300, 300, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 300, 300, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 300, 300, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 150, 150, 128)     0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 150, 150, 256)     295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 150, 150, 256)     590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 150, 150, 256)     590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 75, 75, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 75, 75, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 75, 75, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 75, 75, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 37, 37, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 37, 37, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 37, 37, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 37, 37, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 18, 18, 512)       0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(\"hi\")\n",
    "conv_base=VGG16(weights='imagenet',include_top=False,input_shape=(img_width,img_height,3))\n",
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84bc5c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 240 images belonging to 2 classes.\n",
      "Found 60 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Extract features\n",
    "import os, shutil\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "batch_size = 32\n",
    "\n",
    "def extract_features(directory, sample_count):\n",
    "    features = np.zeros(shape=(sample_count, 18, 18, 512))  # Must be equal to the output of the convolutional base\n",
    "    labels = np.zeros(shape=(sample_count))\n",
    "    # Preprocess data\n",
    "    generator = datagen.flow_from_directory(directory,\n",
    "                                            target_size=(img_width,img_height),\n",
    "                                            batch_size = batch_size,\n",
    "                                            class_mode='binary')\n",
    "    # Pass data through convolutional base\n",
    "    i = 0\n",
    "    for inputs_batch, labels_batch in generator:\n",
    "        features_batch = conv_base.predict(inputs_batch)\n",
    "        features[i * batch_size: (i + 1) * batch_size] = features_batch\n",
    "        labels[i * batch_size: (i + 1) * batch_size] = labels_batch\n",
    "        i += 1\n",
    "        if i * batch_size >= sample_count:\n",
    "            break\n",
    "    return features, labels\n",
    "    \n",
    "train_features, train_labels = extract_features(train_dir, 240)\n",
    "validation_features, validation_labels = extract_features(valid_dir, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b9af8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_features.Flatten()\n",
    "test_features=validation_features\n",
    "test_labels=validation_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5536703",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_flattened = train_features.flatten().reshape(train_features.shape[0],train_features.shape[1]*train_features.shape[2]*train_features.shape[3])\n",
    "test_flattened = test_features.flatten().reshape(test_features.shape[0],test_features.shape[1]*test_features.shape[2]*test_features.shape[3])\n",
    "np.savetxt(\"C:\\\\Users\\\\samba\\\\Downloads\\\\archive\\\\train_sample_features.csv\",train_flattened, delimiter=\",\")\n",
    "np.savetxt(\"C:\\\\Users\\\\samba\\\\Downloads\\\\archive\\\\train_sample_labels.csv\",train_labels, delimiter=\",\")\n",
    "np.savetxt(\"C:\\\\Users\\\\samba\\\\Downloads\\\\archive\\\\test_sample_features.csv\",test_flattened, delimiter=\",\")\n",
    "np.savetxt(\"C:\\\\Users\\\\samba\\\\Downloads\\\\archive\\\\test_sample_labels.csv\",test_labels, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e9f1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 150\n",
    "\n",
    "model = Sequential()\n",
    "model.add(GlobalAveragePooling2D(input_shape=(7,7,512)))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a63a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks.callbacks import ModelCheckpoint\n",
    "checkpoint = ModelCheckpoint('model-{epoch:03d}-{acc:03f}-{val_acc:03f}.h5', verbose=1, monitor='val_loss',save_best_only=True, mode='auto')  \n",
    "\n",
    "# Compile model\n",
    "from keras.optimizers import Adam\n",
    "model.compile(optimizer=Adam(),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "# Train model\n",
    "history = model.fit(train_features, train_labels,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size, \n",
    "                    callbacks=[checkpoint],\n",
    "                    validation_data=(validation_features, validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f5d03f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094de9bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952c9519",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422aa6b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90777080",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "resnet18 = models.resnet18(pretrained=True)\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
